{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yN7Vf8vZHOW9"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import RobertaForSequenceClassification\n",
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#carregando o dataset go_emotions do HuggingFace\n",
        "dataset = load_dataset('go_emotions')"
      ],
      "metadata": {
        "id": "0oel_KHCINsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrfqX4VKJfMI",
        "outputId": "5a565243-7fff-4737-db81-d5e4b268367c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['train', 'validation', 'test'])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['train'][0], len(dataset['train'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbXvhmNcJsJd",
        "outputId": "d53be798-1459-4001-95a7-08cbe48e3965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'text': \"My favourite food is anything I didn't have to cook myself.\",\n",
              "  'labels': [27],\n",
              "  'id': 'eebbqej'},\n",
              " 43410)"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'numero de emoçoes: {len(dataset[\"train\"].features[\"labels\"].feature.names)}\\n')\n",
        "print(f'emoções: {dataset[\"train\"].features[\"labels\"].feature.names}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrWrWNEAPtCH",
        "outputId": "4740277b-4475-444a-92ae-a9e53f1169bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "numero de emoçoes: 28\n",
            "\n",
            "emoções: ['admiration', 'amusement', 'anger', 'annoyance', 'approval', 'caring', 'confusion', 'curiosity', 'desire', 'disappointment', 'disapproval', 'disgust', 'embarrassment', 'excitement', 'fear', 'gratitude', 'grief', 'joy', 'love', 'nervousness', 'optimism', 'pride', 'realization', 'relief', 'remorse', 'sadness', 'surprise', 'neutral']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#instaciando o tokenizer do modelo e criando uma função para tokenizar os dados em batches\n",
        "tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n",
        "\n",
        "def tokenizer_batch(batch):\n",
        "  return tokenizer(batch['text'], padding=\"max_length\", truncation=True, max_length=128)"
      ],
      "metadata": {
        "id": "AA-XIMadKxjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizando os textos dos três conjuntos\n",
        "dataset['train'] = dataset['train'].map(tokenizer_batch, batched=True)\n",
        "dataset['validation'] = dataset['validation'].map(tokenizer_batch, batched=True)\n",
        "dataset['test'] = dataset['test'].map(tokenizer_batch, batched=True)"
      ],
      "metadata": {
        "id": "silTN9r5LsRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#verificando as colunas que o tokenizer criou\n",
        "dataset['train'].column_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDxxTs2-NgwD",
        "outputId": "b1aaa945-76da-4d1c-ff1e-b96368b36e28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['text', 'labels', 'id', 'input_ids', 'attention_mask']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\n",
        "def formatar_labels(batch):\n",
        "    num_labels = 28\n",
        "    novas_labels = []\n",
        "\n",
        "    for labels in batch[\"labels\"]:\n",
        "        vetor = torch.zeros(num_labels)\n",
        "        for label in labels:\n",
        "            vetor[label] = 1\n",
        "        novas_labels.append(vetor)\n",
        "\n",
        "    batch[\"labels\"] = novas_labels\n",
        "    return batch\n",
        "\n",
        "dataset = dataset.map(formatar_labels, batched=True)"
      ],
      "metadata": {
        "id": "_wXLz-_Cv5-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#passando os dados do dataset para tensores\n",
        "colunas_modelo = [\"input_ids\", \"attention_mask\", \"labels\"]\n",
        "\n",
        "dataset['train'].set_format(\"torch\", columns=colunas_modelo)\n",
        "dataset['validation'].set_format(\"torch\", columns=colunas_modelo)\n",
        "dataset['test'].set_format(\"torch\", columns=colunas_modelo)"
      ],
      "metadata": {
        "id": "4KuQ3lQKNHjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defindo os batches\n",
        "batch_treino = DataLoader(dataset[\"train\"], batch_size=16, shuffle=True)\n",
        "batch_validacao = DataLoader(dataset[\"validation\"], batch_size=16)"
      ],
      "metadata": {
        "id": "lyHk6VSCk1u2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#treinamento do modelo\n",
        "modelo = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=28, problem_type=\"multi_label_classification\")"
      ],
      "metadata": {
        "id": "WbLyW54mON-r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#passando o modelo para rodar na GPU, pois vamos usar uma GPU T4 para o fine-tuning\n",
        "gpu = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "modelo.to(gpu)"
      ],
      "metadata": {
        "id": "AaAk0AQohhai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#instaciando o otimizador\n",
        "otimizador = AdamW(modelo.parameters(), lr=2e-5)"
      ],
      "metadata": {
        "id": "kefgn6Z1hhn4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#treinamento do modelo: 4 epocas com batch size de 16, ou seja, a cada 16 amostras o modelo atualiza os pesos.\n",
        "epocas = 4\n",
        "\n",
        "for epoca in range(epocas):\n",
        "    modelo.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in batch_treino:\n",
        "        ids = batch[\"input_ids\"].to(gpu)\n",
        "        mask = batch[\"attention_mask\"].to(gpu)\n",
        "        labels = batch[\"labels\"].to(gpu).float()\n",
        "\n",
        "        output = modelo(input_ids=ids, attention_mask=mask, labels=labels)\n",
        "        loss = output.loss\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        otimizador.step()\n",
        "        otimizador.zero_grad()\n",
        "\n",
        "    print(f\"Época {epoca+1}/{epocas} | Perda média: {total_loss / len(batch_treino):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3kKtpoujBwE",
        "outputId": "57a719dc-a56a-4133-f8eb-915742ab9f5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Época 1/4 | Perda média: 0.1193\n",
            "Época 2/4 | Perda média: 0.0851\n",
            "Época 3/4 | Perda média: 0.0758\n",
            "Época 4/4 | Perda média: 0.0676\n"
          ]
        }
      ]
    }
  ]
}
